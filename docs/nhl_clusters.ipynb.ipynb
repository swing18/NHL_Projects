{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_scoring_seasons(season_start, season_end):\n",
    "    # Get the summary JSON data\n",
    "    scoring_stats_url = f\"https://api.nhle.com/stats/rest/en/skater/summary?isAggregate=true&isGame=false&sort=%5B%7B%22property%22:%22points%22,%22direction%22:%22DESC%22%7D,%7B%22property%22:%22goals%22,%22direction%22:%22DESC%22%7D,%7B%22property%22:%22assists%22,%22direction%22:%22DESC%22%7D,%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D&start=0&limit=-1&cayenneExp=gameTypeId=2%20and%20seasonId%3C={season_end}%20and%20seasonId%3E={season_start}\"\n",
    "    scoring_stats_data = requests.get(scoring_stats_url).json()[\"data\"]\n",
    "\n",
    "    # Convert to DataFrame and select/rename desired columns\n",
    "    scoring_stats_df = pd.json_normalize(scoring_stats_data)\n",
    "    scoring_stats_df = scoring_stats_df.rename(columns={\n",
    "        \"playerId\": \"player_id\",\n",
    "        \"skaterFullName\": \"player\",\n",
    "        \"positionCode\": \"position\",\n",
    "        \"evGoals\": \"es_goals\",\n",
    "        \"evPoints\": \"es_points\",\n",
    "        \"ppGoals\": \"pp_goals\",\n",
    "        \"ppPoints\": \"pp_points\",\n",
    "        \"shGoals\": \"sh_goals\",\n",
    "        \"shPoints\": \"sh_points\",\n",
    "        \"otGoals\": \"ot_goals\"\n",
    "    })[[\n",
    "        \"player_id\", \"player\", \"position\", \"goals\", \"assists\", \"points\", \n",
    "        \"es_goals\", \"es_points\", \"pp_goals\", \"pp_points\", \"sh_goals\", \"sh_points\", \"ot_goals\"\n",
    "    ]]\n",
    "\n",
    "    # Add missing assists\n",
    "    scoring_stats_df[\"es_assists\"] = scoring_stats_df[\"es_points\"] - scoring_stats_df[\"es_goals\"]\n",
    "    scoring_stats_df[\"pp_assists\"] = scoring_stats_df[\"pp_points\"] - scoring_stats_df[\"pp_goals\"]\n",
    "    scoring_stats_df[\"sh_assists\"] = scoring_stats_df[\"sh_points\"] - scoring_stats_df[\"sh_goals\"]\n",
    "\n",
    "    # Add proportions\n",
    "    scoring_stats_df[\"es_goals_proportion\"] = scoring_stats_df[\"es_goals\"] / scoring_stats_df[\"goals\"]\n",
    "    scoring_stats_df[\"pp_goals_proportion\"] = scoring_stats_df[\"pp_goals\"] / scoring_stats_df[\"goals\"]\n",
    "    scoring_stats_df[\"sh_goals_proportion\"] = scoring_stats_df[\"sh_goals\"] / scoring_stats_df[\"goals\"]\n",
    "    scoring_stats_df[\"ot_goals_proportion\"] = scoring_stats_df[\"ot_goals\"] / scoring_stats_df[\"goals\"]\n",
    "    scoring_stats_df[\"es_assists_proportion\"] = scoring_stats_df[\"es_assists\"] / scoring_stats_df[\"assists\"]\n",
    "    scoring_stats_df[\"pp_assists_proportion\"] = scoring_stats_df[\"pp_assists\"] / scoring_stats_df[\"assists\"]\n",
    "    scoring_stats_df[\"sh_assists_proportion\"] = scoring_stats_df[\"sh_assists\"] / scoring_stats_df[\"assists\"]\n",
    "    scoring_stats_df[\"es_points_proportion\"] = scoring_stats_df[\"es_points\"] / scoring_stats_df[\"points\"]\n",
    "    scoring_stats_df[\"pp_points_proportion\"] = scoring_stats_df[\"pp_points\"] / scoring_stats_df[\"points\"]\n",
    "    scoring_stats_df[\"sh_points_proportion\"] = scoring_stats_df[\"sh_points\"] / scoring_stats_df[\"points\"]\n",
    "\n",
    "    # Change position to F/D\n",
    "    scoring_stats_df[\"position\"] = scoring_stats_df[\"position\"].apply(lambda x: \"D\" if x == \"D\" else \"F\")\n",
    "\n",
    "    # Arrange data by descending points\n",
    "    scoring_stats_df = scoring_stats_df.sort_values(by=\"points\", ascending=False)\n",
    "\n",
    "    # Add on-ice goals-for data\n",
    "    oi_stats_url = f\"https://api.nhle.com/stats/rest/en/skater/goalsForAgainst?isAggregate=true&isGame=false&sort=%5B%7B%22property%22:%22evenStrengthGoalDifference%22,%22direction%22:%22DESC%22%7D,%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D&start=0&limit=-1&cayenneExp=gameTypeId=2%20and%20seasonId%3C={season_end}%20and%20seasonId%3E={season_start}\"\n",
    "    oi_stats_data = requests.get(oi_stats_url).json()[\"data\"]\n",
    "\n",
    "    oi_stats_df = pd.json_normalize(oi_stats_data)\n",
    "    oi_stats_df = oi_stats_df.rename(columns={\n",
    "        \"playerId\": \"player_id\",\n",
    "        \"evenStrengthGoalsFor\": \"oi_es_goals_for\",\n",
    "        \"powerPlayGoalFor\": \"oi_pp_goals_for\",\n",
    "        \"shortHandedGoalsFor\": \"oi_sh_goals_for\"\n",
    "    })[[\"player_id\", \"oi_es_goals_for\", \"oi_pp_goals_for\", \"oi_sh_goals_for\"]]\n",
    "\n",
    "    # Join the on-ice data to the general scoring data\n",
    "    scoring_stats_df = scoring_stats_df.merge(oi_stats_df, on=\"player_id\", how=\"left\").fillna(0)\n",
    "\n",
    "    # Add on-ice data excluding the skater's own goals\n",
    "    scoring_stats_df[\"oi_es_gf_xskater\"] = scoring_stats_df[\"oi_es_goals_for\"] - scoring_stats_df[\"es_goals\"]\n",
    "    scoring_stats_df[\"oi_pp_gf_xskater\"] = scoring_stats_df[\"oi_pp_goals_for\"] - scoring_stats_df[\"pp_goals\"]\n",
    "    scoring_stats_df[\"oi_sh_gf_xskater\"] = scoring_stats_df[\"oi_sh_goals_for\"] - scoring_stats_df[\"sh_goals\"]\n",
    "\n",
    "    # Add A1/A2 data [all strengths and power play]\n",
    "    a1_a2_stats_url = f\"https://api.nhle.com/stats/rest/en/skater/scoringpergame?isAggregate=true&isGame=false&sort=%5B%7B%22property%22:%22pointsPerGame%22,%22direction%22:%22DESC%22%7D,%7B%22property%22:%22goalsPerGame%22,%22direction%22:%22DESC%22%7D,%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D&start=0&limit=-1&cayenneExp=gameTypeId=2%20and%20seasonId%3C={season_end}%20and%20seasonId%3E={season_start}\"\n",
    "    a1_a2_stats_data = requests.get(a1_a2_stats_url).json()[\"data\"]\n",
    "\n",
    "    a1_a2_stats_df = pd.json_normalize(a1_a2_stats_data)\n",
    "    a1_a2_stats_df = a1_a2_stats_df.rename(columns={\n",
    "        \"playerId\": \"player_id\",\n",
    "        \"totalPrimaryAssists\": \"primary_assists\",\n",
    "        \"totalSecondaryAssists\": \"secondary_assists\"\n",
    "    })[[\"player_id\", \"primary_assists\", \"secondary_assists\"]]\n",
    "\n",
    "    a1_a2_stats_df[\"primary_a_proportion\"] = a1_a2_stats_df[\"primary_assists\"] / (a1_a2_stats_df[\"primary_assists\"] + a1_a2_stats_df[\"secondary_assists\"])\n",
    "\n",
    "    # Join the A1/A2 data to the general scoring data\n",
    "    scoring_stats_df = scoring_stats_df.merge(a1_a2_stats_df.drop(columns=\"secondary_assists\"), on=\"player_id\", how=\"left\")\n",
    "\n",
    "    # Repeat for power play A1/A2 data\n",
    "    a1_a2_pp_stats_url = f\"https://api.nhle.com/stats/rest/en/skater/powerplay?isAggregate=true&isGame=false&sort=%5B%7B%22property%22:%22ppTimeOnIce%22,%22direction%22:%22DESC%22%7D,%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D&start=0&limit=-1&cayenneExp=gameTypeId=2%20and%20seasonId%3C={season_end}%20and%20seasonId%3E={season_start}\"\n",
    "    a1_a2_pp_stats_data = requests.get(a1_a2_pp_stats_url).json()[\"data\"]\n",
    "\n",
    "    a1_a2_pp_stats_df = pd.json_normalize(a1_a2_pp_stats_data)\n",
    "    a1_a2_pp_stats_df = a1_a2_pp_stats_df.rename(columns={\n",
    "        \"playerId\": \"player_id\",\n",
    "        \"ppPrimaryAssists\": \"pp_primary_assists\",\n",
    "        \"ppSecondaryAssists\": \"pp_secondary_assists\"\n",
    "    })[[\"player_id\", \"pp_primary_assists\", \"pp_secondary_assists\"]]\n",
    "\n",
    "    a1_a2_pp_stats_df[\"pp_primary_a_proportion\"] = a1_a2_pp_stats_df[\"pp_primary_assists\"] / (a1_a2_pp_stats_df[\"pp_primary_assists\"] + a1_a2_pp_stats_df[\"pp_secondary_assists\"])\n",
    "\n",
    "    # Join the A1/A2 PP data to the general scoring data\n",
    "    scoring_stats_df = scoring_stats_df.merge(a1_a2_pp_stats_df.drop(columns=\"pp_secondary_assists\"), on=\"player_id\", how=\"left\")\n",
    "\n",
    "    return scoring_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#empy net is being funky and all EN stats are missing here currently\n",
    "def get_scoring_dates(date_start, date_end):\n",
    "    \n",
    "    # Function to handle API requests and return JSON data\n",
    "    def get_api_data(url):\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "        return response.json()['data']\n",
    "    \n",
    "    # Construct URLs for the API requests\n",
    "    scoring_stats_url = (\n",
    "        f\"https://api.nhle.com/stats/rest/en/skater/summary?\"\n",
    "        f\"isAggregate=true&isGame=true&sort=%5B%7B%22property%22:%22points%22,%22direction%22:%22DESC%22%7D,\"\n",
    "        f\"%7B%22property%22:%22goals%22,%22direction%22:%22DESC%22%7D,%7B%22property%22:%22assists%22,%22direction%22:%22DESC%22%7D,\"\n",
    "        f\"%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D&start=0&limit=-1&cayenneExp=gameDate%3C=%22\"\n",
    "        f\"{date_end}%2023%3A59%3A59%22%20and%20gameDate%3E=%22{date_start}%22%20and%20gameTypeId=2\"\n",
    "    )\n",
    "    \n",
    "    # Get and process the scoring stats data\n",
    "    scoring_stats_data = pd.json_normalize(get_api_data(scoring_stats_url))\n",
    "    \n",
    "    # Select and rename the desired columns\n",
    "    scoring_stats_data = scoring_stats_data.rename(columns={\n",
    "        'playerId': 'player_id',\n",
    "        'skaterFullName': 'player',\n",
    "        'positionCode': 'position',\n",
    "        'evGoals': 'es_goals',\n",
    "        'evPoints': 'es_points',\n",
    "        'ppGoals': 'pp_goals',\n",
    "        'ppPoints': 'pp_points',\n",
    "        'shGoals': 'sh_goals',\n",
    "        'shPoints': 'sh_points',\n",
    "        'otGoals': 'ot_goals'\n",
    "    }).filter([\n",
    "        'player_id', 'player', 'position', 'goals', 'assists', 'points', \n",
    "        'es_goals', 'es_points', 'pp_goals', 'pp_points', 'sh_goals', \n",
    "        'sh_points', 'ot_goals'\n",
    "    ])\n",
    "    \n",
    "    # Add missing assists\n",
    "    scoring_stats_data['es_assists'] = scoring_stats_data['es_points'] - scoring_stats_data['es_goals']\n",
    "    scoring_stats_data['pp_assists'] = scoring_stats_data['pp_points'] - scoring_stats_data['pp_goals']\n",
    "    scoring_stats_data['sh_assists'] = scoring_stats_data['sh_points'] - scoring_stats_data['sh_goals']\n",
    "    \n",
    "    # Add proportions\n",
    "    for col in ['es', 'pp', 'sh']:\n",
    "        scoring_stats_data[f'{col}_goals_proportion'] = scoring_stats_data[f'{col}_goals'] / scoring_stats_data['goals']\n",
    "        scoring_stats_data[f'{col}_assists_proportion'] = scoring_stats_data[f'{col}_assists'] / scoring_stats_data['assists']\n",
    "        scoring_stats_data[f'{col}_points_proportion'] = scoring_stats_data[f'{col}_points'] / scoring_stats_data['points']\n",
    "    \n",
    "    # Add overtime goals proportion\n",
    "    scoring_stats_data['ot_goals_proportion'] = scoring_stats_data['ot_goals'] / scoring_stats_data['goals']\n",
    "    \n",
    "    # Change position to F/D\n",
    "    scoring_stats_data['position'] = np.where(scoring_stats_data['position'] == 'D', 'D', 'F')\n",
    "    \n",
    "    # Sort data by descending points\n",
    "    scoring_stats_data = scoring_stats_data.sort_values(by='points', ascending=False)\n",
    "    \n",
    "    # Process on-ice goals-for data\n",
    "    oi_stats_url = (\n",
    "        f\"https://api.nhle.com/stats/rest/en/skater/goalsForAgainst?\"\n",
    "        f\"isAggregate=true&isGame=true&sort=%5B%7B%22property%22:%22evenStrengthGoalDifference%22,%22direction%22:%22DESC%22%7D,\"\n",
    "        f\"%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D&start=0&limit=-1&cayenneExp=gameDate%3C=%22\"\n",
    "        f\"{date_end}%2023%3A59%3A59%22%20and%20gameDate%3E=%22{date_start}%22%20and%20gameTypeId=2\"\n",
    "    )\n",
    "    \n",
    "    oi_stats_data = pd.json_normalize(get_api_data(oi_stats_url)).rename(columns={\n",
    "        'playerId': 'player_id',\n",
    "        'evenStrengthGoalsFor': 'oi_es_goals_for',\n",
    "        'powerPlayGoalFor': 'oi_pp_goals_for',\n",
    "        'shortHandedGoalsFor': 'oi_sh_goals_for'\n",
    "    })\n",
    "    \n",
    "    # Join the on-ice data to the general scoring data\n",
    "    scoring_stats_data = scoring_stats_data.merge(oi_stats_data, on='player_id', how='left').fillna(0)\n",
    "    \n",
    "    # Add on-ice data excluding the skater's own goals\n",
    "    scoring_stats_data['oi_es_gf_xskater'] = scoring_stats_data['oi_es_goals_for'] - scoring_stats_data['es_goals']\n",
    "    scoring_stats_data['oi_pp_gf_xskater'] = scoring_stats_data['oi_pp_goals_for'] - scoring_stats_data['pp_goals']\n",
    "    scoring_stats_data['oi_sh_gf_xskater'] = scoring_stats_data['oi_sh_goals_for'] - scoring_stats_data['sh_goals']\n",
    "    \n",
    "    # Process A1/A2 data (all strengths and power play)\n",
    "    a1_a2_stats_url = (\n",
    "        f\"https://api.nhle.com/stats/rest/en/skater/scoringpergame?\"\n",
    "        f\"isAggregate=true&isGame=true&sort=%5B%7B%22property%22:%22pointsPerGame%22,%22direction%22:%22DESC%22%7D,\"\n",
    "        f\"%7B%22property%22:%22goalsPerGame%22,%22direction%22:%22DESC%22%7D,\"\n",
    "        f\"%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D&start=0&limit=-1&cayenneExp=gameDate%3C=%22\"\n",
    "        f\"{date_end}%2023%3A59%3A59%22%20and%20gameDate%3E=%22{date_start}%22%20and%20gameTypeId=2\"\n",
    "    )\n",
    "    \n",
    "    a1_a2_stats_data = pd.json_normalize(get_api_data(a1_a2_stats_url)).rename(columns={\n",
    "        'playerId': 'player_id',\n",
    "        'totalPrimaryAssists': 'primary_assists',\n",
    "        'totalSecondaryAssists': 'secondary_assists'\n",
    "    })\n",
    "    \n",
    "    a1_a2_stats_data['primary_a_proportion'] = a1_a2_stats_data['primary_assists'] / a1_a2_stats_data['assists']\n",
    "    \n",
    "    scoring_stats_data = scoring_stats_data.merge(a1_a2_stats_data.drop(columns=['assists']), on='player_id', how='left').fillna(0)\n",
    "    \n",
    "    # Process power play A1/A2 data\n",
    "    a1_a2_pp_stats_url = (\n",
    "        f\"https://api.nhle.com/stats/rest/en/skater/powerplay?\"\n",
    "        f\"isAggregate=true&isGame=true&sort=%5B%7B%22property%22:%22ppTimeOnIce%22,%22direction%22:%22DESC%22%7D,\"\n",
    "        f\"%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D&start=0&limit=-1&cayenneExp=gameDate%3C=%22\"\n",
    "        f\"{date_end}%2023%3A59%3A59%22%20and%20gameDate%3E=%22{date_start}%22%20and%20gameTypeId=2\"\n",
    "    )\n",
    "    \n",
    "    a1_a2_pp_stats_data = pd.json_normalize(get_api_data(a1_a2_pp_stats_url)).rename(columns={\n",
    "        'playerId': 'player_id',\n",
    "        'ppPrimaryAssists': 'pp_primary_assists',\n",
    "        'ppSecondaryAssists': 'pp_secondary_assists'\n",
    "    })\n",
    "    \n",
    "    a1_a2_pp_stats_data['pp_primary_a_proportion'] = a1_a2_pp_stats_data['pp_primary_assists'] / a1_a2_pp_stats_data['ppAssists']\n",
    "    \n",
    "    scoring_stats_data = scoring_stats_data.merge(a1_a2_pp_stats_data.drop(columns=['ppAssists']), on='player_id', how='left').fillna(0)\n",
    "    \n",
    "    # Process empty-net and game-winning goals\n",
    "\n",
    "\n",
    "#     en_stats_url = (\n",
    "#         f\"https://api.nhle.com/stats/rest/en/skater/realtime?isAggregate=true&isGame=false\"\n",
    "#         f\"&sort=%5B%7B%22property%22:%22hits%22,%22direction%22:%22DESC%22%7D,\"\n",
    "#         f\"%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D\"\n",
    "#         f\"&start=0&limit=-1&cayenneExp=gameTypeId=2%20and%20seasonId%3C={date_end}%20and%20seasonId%3E={date_start}\"\n",
    "# )\n",
    "#     en_stats_data = pd.json_normalize(get_api_data(en_stats_url)).rename(columns={\n",
    "#         'playerId': 'player_id',\n",
    "#         'emptyNetGoals': 'en_goals',\n",
    "#         'gameWinningGoals': 'gw_goals'\n",
    "#     })\n",
    "    \n",
    "    #scoring_stats_data = scoring_stats_data.merge(en_stats_data, on='player_id', how='left').fillna(0)\n",
    "    \n",
    "    # Select final columns for the output\n",
    "    scoring_stats_data = scoring_stats_data.filter([\n",
    "        'player_id', 'player', 'position', 'goals', 'assists', 'points', 'primary_assists',\n",
    "        'secondary_assists', 'primary_a_proportion', 'en_goals', 'gw_goals', 'es_goals',\n",
    "        'es_assists', 'es_points', 'es_goals_proportion', 'es_assists_proportion', 'es_points_proportion',\n",
    "        'pp_goals', 'pp_assists', 'pp_points', 'pp_goals_proportion', 'pp_assists_proportion', \n",
    "        'pp_points_proportion', 'pp_primary_assists', 'pp_secondary_assists', 'pp_primary_a_proportion',\n",
    "        'sh_goals', 'sh_assists', 'sh_points', 'sh_goals_proportion', 'sh_assists_proportion', \n",
    "        'sh_points_proportion', 'oi_es_goals_for', 'oi_es_gf_xskater', 'oi_pp_goals_for', \n",
    "        'oi_pp_gf_xskater', 'oi_sh_goals_for', 'oi_sh_gf_xskater', 'ot_goals', 'ot_goals_proportion'\n",
    "    ]).sort_values(by='points', ascending=False)\n",
    "    \n",
    "    return scoring_stats_data\n",
    "\n",
    "# Example usage\n",
    "date_start = \"2024-01-01\"\n",
    "date_end = \"2024-02-01\"\n",
    "df = get_scoring_dates(date_start = \"2023-01-01\",\n",
    "                                       date_end = \"2024-04-18\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_toi_dates(date_start, date_end, rounding=True):\n",
    "    # Construct the URL for the API request\n",
    "    toi_stats_url = (\n",
    "        f\"https://api.nhle.com/stats/rest/en/skater/timeonice?\"\n",
    "        f\"isAggregate=true&isGame=true&sort=%5B%7B%22property%22:%22timeOnIce%22,%22direction%22:%22DESC%22%7D,%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D\"\n",
    "        f\"&start=0&limit=-1&cayenneExp=gameDate%3C=%22{date_end}%2023%3A59%3A59%22%20and%20gameDate%3E=%22{date_start}%22%20and%20gameTypeId=2\"\n",
    "    )\n",
    "\n",
    "    # Get the JSON data from the API\n",
    "    response = requests.get(toi_stats_url)\n",
    "    response.raise_for_status()  # Ensure the request was successful\n",
    "    toi_stats_data = response.json()['data']\n",
    "\n",
    "    # Convert the JSON data to a pandas DataFrame\n",
    "    df = pd.json_normalize(toi_stats_data)\n",
    "\n",
    "    # Select and rename the desired columns\n",
    "    df = df.rename(columns={\n",
    "        'playerId': 'player_id',\n",
    "        'skaterFullName': 'player',\n",
    "        'positionCode': 'position',\n",
    "        'gamesPlayed': 'games_played',\n",
    "        'timeOnIce': 'toi_total',\n",
    "        'timeOnIcePerGame': 'toi_gp',\n",
    "        'timeOnIcePerShift': 'toi_shift',\n",
    "        'shifts': 'shifts',\n",
    "        'shiftsPerGame': 'shifts_gp',\n",
    "        'evTimeOnIce': 'toi_es_total',\n",
    "        'evTimeOnIcePerGame': 'toi_es_gp',\n",
    "        'ppTimeOnIce': 'toi_pp_total',\n",
    "        'ppTimeOnIcePerGame': 'toi_pp_gp',\n",
    "        'shTimeOnIce': 'toi_sh_total',\n",
    "        'shTimeOnIcePerGame': 'toi_sh_gp',\n",
    "        'otTimeOnIce': 'toi_ot_total',\n",
    "        'otTimeOnIcePerOtGame': 'toi_ot_per_ot_gp'\n",
    "    })\n",
    "\n",
    "    # Change position to F/D\n",
    "    df['position'] = df['position'].apply(lambda x: 'D' if x == 'D' else 'F')\n",
    "\n",
    "    # Fill NAs in OT data with 0s\n",
    "    df['toi_ot_per_ot_gp'] = df['toi_ot_per_ot_gp'].fillna(0)\n",
    "\n",
    "    # Arrange data by descending TOI/GP\n",
    "    df = df.sort_values(by='toi_gp', ascending=False)\n",
    "\n",
    "    # Add proportion of total TOI that is ES, PP, SH, OT\n",
    "    df['proportion_es'] = (df['toi_es_total'] / df['toi_total']).round(3)\n",
    "    df['proportion_pp'] = (df['toi_pp_total'] / df['toi_total']).round(3)\n",
    "    df['proportion_sh'] = (df['toi_sh_total'] / df['toi_total']).round(3)\n",
    "    df['proportion_ot'] = (df['toi_ot_total'] / df['toi_total']).round(3)\n",
    "\n",
    "    # Apply the rounding argument\n",
    "    if rounding:\n",
    "        rounding_columns = [col for col in df.columns if col.endswith('_gp') or col.endswith('_shift')]\n",
    "        df[rounding_columns] = df[rounding_columns].round()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_toi_seasons(season_start, season_end, aggregate_data=False, rounding=True):\n",
    "    # Prepare the aggregate_data argument\n",
    "    agg_data_arg = 'true' if aggregate_data else 'false'\n",
    "    \n",
    "    # Get the JSON data\n",
    "    toi_stats_url = (\n",
    "        f\"https://api.nhle.com/stats/rest/en/skater/timeonice?\"\n",
    "        f\"isAggregate={agg_data_arg}&isGame=false&sort=%5B%7B%22property%22:%22timeOnIce%22,%22direction%22:%22DESC%22%7D,%7B%22property%22:%22playerId%22,%22direction%22:%22ASC%22%7D%5D\"\n",
    "        f\"&start=0&limit=-1&cayenneExp=gameTypeId=2%20and%20seasonId%3C={season_end}%20and%20seasonId%3E={season_start}\"\n",
    "    )\n",
    "    \n",
    "    response = requests.get(toi_stats_url)\n",
    "    response.raise_for_status()  # Ensure we notice bad responses\n",
    "    toi_stats_data = response.json()['data']\n",
    "    \n",
    "    # Convert JSON data to DataFrame\n",
    "    df = pd.json_normalize(toi_stats_data)\n",
    "    \n",
    "    # Select and rename the desired columns\n",
    "    if not aggregate_data:\n",
    "        df = df.rename(columns={\n",
    "            'playerId': 'player_id',\n",
    "            'skaterFullName': 'player',\n",
    "            'seasonId': 'season',\n",
    "            'positionCode': 'position',\n",
    "            'gamesPlayed': 'games_played',\n",
    "            'timeOnIce': 'toi_total',\n",
    "            'timeOnIcePerGame': 'toi_gp',\n",
    "            'timeOnIcePerShift': 'toi_shift',\n",
    "            'shifts': 'shifts',\n",
    "            'shiftsPerGame': 'shifts_gp',\n",
    "            'evTimeOnIce': 'toi_es_total',\n",
    "            'evTimeOnIcePerGame': 'toi_es_gp',\n",
    "            'ppTimeOnIce': 'toi_pp_total',\n",
    "            'ppTimeOnIcePerGame': 'toi_pp_gp',\n",
    "            'shTimeOnIce': 'toi_sh_total',\n",
    "            'shTimeOnIcePerGame': 'toi_sh_gp',\n",
    "            'otTimeOnIce': 'toi_ot_total',\n",
    "            'otTimeOnIcePerOtGame': 'toi_ot_per_ot_gp'\n",
    "        })\n",
    "    else:\n",
    "        df = df.rename(columns={\n",
    "            'playerId': 'player_id',\n",
    "            'skaterFullName': 'player',\n",
    "            'positionCode': 'position',\n",
    "            'gamesPlayed': 'games_played',\n",
    "            'timeOnIce': 'toi_total',\n",
    "            'timeOnIcePerGame': 'toi_gp',\n",
    "            'timeOnIcePerShift': 'toi_shift',\n",
    "            'shifts': 'shifts',\n",
    "            'shiftsPerGame': 'shifts_gp',\n",
    "            'evTimeOnIce': 'toi_es_total',\n",
    "            'evTimeOnIcePerGame': 'toi_es_gp',\n",
    "            'ppTimeOnIce': 'toi_pp_total',\n",
    "            'ppTimeOnIcePerGame': 'toi_pp_gp',\n",
    "            'shTimeOnIce': 'toi_sh_total',\n",
    "            'shTimeOnIcePerGame': 'toi_sh_gp',\n",
    "            'otTimeOnIce': 'toi_ot_total',\n",
    "            'otTimeOnIcePerOtGame': 'toi_ot_per_ot_gp'\n",
    "        })\n",
    "    \n",
    "    # Change position to F/D\n",
    "    df['position'] = df['position'].apply(lambda x: 'D' if x == 'D' else 'F')\n",
    "    \n",
    "    # Fill NAs in OT data with 0s\n",
    "    df['toi_ot_per_ot_gp'] = df['toi_ot_per_ot_gp'].fillna(0)\n",
    "    \n",
    "    # Arrange data by descending TOI/GP\n",
    "    df = df.sort_values(by='toi_gp', ascending=False)\n",
    "    \n",
    "    # Add proportion of total TOI that is ES, PP, SH, OT\n",
    "    df['proportion_es'] = (df['toi_es_total'] / df['toi_total']).round(3)\n",
    "    df['proportion_pp'] = (df['toi_pp_total'] / df['toi_total']).round(3)\n",
    "    df['proportion_sh'] = (df['toi_sh_total'] / df['toi_total']).round(3)\n",
    "    df['proportion_ot'] = (df['toi_ot_total'] / df['toi_total']).round(3)\n",
    "    \n",
    "    # Apply the rounding argument\n",
    "    if rounding:\n",
    "        rounding_columns = [col for col in df.columns if col.endswith('_gp') or col.endswith('_shift')]\n",
    "        df[rounding_columns] = df[rounding_columns].round()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import percentileofscore\n",
    "players_df=get_toi_seasons(20232024,20242025)\n",
    "\n",
    "\n",
    "# Step 1: Drop all rows where 'games_played' is below 40\n",
    "players_df = players_df[players_df['games_played'] >= 40]\n",
    "\n",
    "# Step 2: Keep only the desired columns\n",
    "columns_to_keep = ['player', 'toi_pp_gp', 'toi_sh_gp', 'toi_es_gp', 'toi_ot_per_ot_gp', 'games_played', 'position']\n",
    "players_df = players_df[columns_to_keep]\n",
    "\n",
    "# Split the DataFrame into forwards and defensemen\n",
    "forwards_df = players_df[players_df['position'] == 'F'].copy()\n",
    "defense_df = players_df[players_df['position'] == 'D'].copy()\n",
    "\n",
    "# Define a function to calculate percentiles for a specific column\n",
    "def calculate_percentile(df, column):\n",
    "    return df[column].apply(lambda x: percentileofscore(df[column], x))\n",
    "\n",
    "# Calculate percentiles for each category\n",
    "for column in ['toi_pp_gp', 'toi_sh_gp', 'toi_es_gp','toi_ot_per_ot_gp']:\n",
    "    forwards_df[f'{column}_percentile'] = calculate_percentile(forwards_df, column)\n",
    "    defense_df[f'{column}_percentile'] = calculate_percentile(defense_df, column)\n",
    "\n",
    "# Now forwards_df and defense_df contain the percentile rankings for each player in their respective categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>toi_pp_gp</th>\n",
       "      <th>toi_sh_gp</th>\n",
       "      <th>toi_es_gp</th>\n",
       "      <th>toi_ot_per_ot_gp</th>\n",
       "      <th>games_played</th>\n",
       "      <th>position</th>\n",
       "      <th>toi_pp_gp_percentile</th>\n",
       "      <th>toi_sh_gp_percentile</th>\n",
       "      <th>toi_es_gp_percentile</th>\n",
       "      <th>toi_ot_per_ot_gp_percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mikko Rantanen</td>\n",
       "      <td>276.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>80</td>\n",
       "      <td>F</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>25.985222</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>89.901478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nathan MacKinnon</td>\n",
       "      <td>270.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>82</td>\n",
       "      <td>F</td>\n",
       "      <td>99.507389</td>\n",
       "      <td>32.389163</td>\n",
       "      <td>99.753695</td>\n",
       "      <td>98.891626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Nikita Kucherov</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>99.014778</td>\n",
       "      <td>6.773399</td>\n",
       "      <td>99.507389</td>\n",
       "      <td>84.359606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Kirill Kaprizov</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>75</td>\n",
       "      <td>F</td>\n",
       "      <td>99.261084</td>\n",
       "      <td>25.985222</td>\n",
       "      <td>99.014778</td>\n",
       "      <td>99.507389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Vincent Trocheck</td>\n",
       "      <td>209.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82</td>\n",
       "      <td>F</td>\n",
       "      <td>92.610837</td>\n",
       "      <td>73.891626</td>\n",
       "      <td>96.428571</td>\n",
       "      <td>89.162562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Walker Duehr</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>16.009852</td>\n",
       "      <td>29.310345</td>\n",
       "      <td>1.231527</td>\n",
       "      <td>9.975369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>Ryan Reaves</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>8.990148</td>\n",
       "      <td>6.773399</td>\n",
       "      <td>1.847291</td>\n",
       "      <td>9.975369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Michael Pezzetta</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>5.295567</td>\n",
       "      <td>38.423645</td>\n",
       "      <td>0.738916</td>\n",
       "      <td>9.975369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Mark Kastelic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "      <td>F</td>\n",
       "      <td>12.192118</td>\n",
       "      <td>36.945813</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>9.975369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>Kurtis MacDermid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "      <td>0.615764</td>\n",
       "      <td>6.773399</td>\n",
       "      <td>0.246305</td>\n",
       "      <td>9.975369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               player  toi_pp_gp  toi_sh_gp  toi_es_gp  toi_ot_per_ot_gp  \\\n",
       "31     Mikko Rantanen      276.0        2.0     1097.0              79.0   \n",
       "20   Nathan MacKinnon      270.0        4.0     1095.0             104.0   \n",
       "39    Nikita Kucherov      243.0        0.0     1057.0              70.0   \n",
       "76    Kirill Kaprizov      250.0        2.0     1043.0             112.0   \n",
       "38   Vincent Trocheck      209.0       95.0      984.0              78.0   \n",
       "..                ...        ...        ...        ...               ...   \n",
       "676      Walker Duehr        6.0        3.0      477.0               0.0   \n",
       "650       Ryan Reaves        3.0        0.0      484.0               0.0   \n",
       "622  Michael Pezzetta        2.0        8.0      458.0               0.0   \n",
       "618     Mark Kastelic        4.0        7.0      453.0               0.0   \n",
       "718  Kurtis MacDermid        0.0        0.0      290.0               0.0   \n",
       "\n",
       "     games_played position  toi_pp_gp_percentile  toi_sh_gp_percentile  \\\n",
       "31             80        F            100.000000             25.985222   \n",
       "20             82        F             99.507389             32.389163   \n",
       "39             81        F             99.014778              6.773399   \n",
       "76             75        F             99.261084             25.985222   \n",
       "38             82        F             92.610837             73.891626   \n",
       "..            ...      ...                   ...                   ...   \n",
       "676            40        F             16.009852             29.310345   \n",
       "650            49        F              8.990148              6.773399   \n",
       "622            61        F              5.295567             38.423645   \n",
       "618            63        F             12.192118             36.945813   \n",
       "718            45        F              0.615764              6.773399   \n",
       "\n",
       "     toi_es_gp_percentile  toi_ot_per_ot_gp_percentile  \n",
       "31             100.000000                    89.901478  \n",
       "20              99.753695                    98.891626  \n",
       "39              99.507389                    84.359606  \n",
       "76              99.014778                    99.507389  \n",
       "38              96.428571                    89.162562  \n",
       "..                    ...                          ...  \n",
       "676              1.231527                     9.975369  \n",
       "650              1.847291                     9.975369  \n",
       "622              0.738916                     9.975369  \n",
       "618              0.492611                     9.975369  \n",
       "718              0.246305                     9.975369  \n",
       "\n",
       "[406 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "forwards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "import pandas as pd\n",
    "\n",
    "# Select the relevant columns for clustering\n",
    "percentile_columns = ['toi_pp_gp_percentile', 'toi_sh_gp_percentile', 'toi_es_gp_percentile', 'toi_ot_per_ot_gp_percentile']\n",
    "data_for_clustering = forwards_df[percentile_columns]\n",
    "\n",
    "# Initialize and fit HDBSCAN\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=1)\n",
    "cluster_labels = clusterer.fit_predict(data_for_clustering)\n",
    "\n",
    "# Add the cluster labels to your DataFrame\n",
    "forwards_df['cluster'] = cluster_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to make unfilterable chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from umap import UMAP\n",
    "\n",
    "\n",
    "\n",
    "# Reducing to 2D space using UMAP\n",
    "umap_model = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric=\"cosine\")\n",
    "percentile_columns = ['toi_pp_gp_percentile', 'toi_sh_gp_percentile', 'toi_es_gp_percentile', 'toi_ot_per_ot_gp_percentile']\n",
    "reduced_embeddings = umap_model.fit_transform(forwards_df[percentile_columns])\n",
    "\n",
    "# Add the reduced 2D embeddings to the DataFrame\n",
    "forwards_df['x'] = reduced_embeddings[:, 0]\n",
    "forwards_df['y'] = reduced_embeddings[:, 1]\n",
    "\n",
    "# Create the scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "    x=forwards_df['x'],\n",
    "    y=forwards_df['y'],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, opacity=0.7),\n",
    "    text=forwards_df.apply(lambda row: f\"Player: {row['player']}<br>PP Percentile: {row['toi_pp_gp_percentile']}<br>SH Percentile: {row['toi_sh_gp_percentile']}<br>ES Percentile: {row['toi_es_gp_percentile']}<br>OT Percentile: {row['toi_ot_per_ot_gp_percentile']}\", axis=1),\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Stylize layout\n",
    "fig.update_layout(\n",
    "    template=\"simple_white\",\n",
    "    title={\n",
    "        \"text\": \"<b>Player Percentiles Mapped to 2D Space</b>\",\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"yanchor\": \"top\",\n",
    "        \"font\": dict(size=22, color=\"Black\"),\n",
    "    },\n",
    "    width=1200,\n",
    "    height=750,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(visible=False)\n",
    "fig.update_yaxes(visible=False)\n",
    "\n",
    "# export the plot\n",
    "fig.write_html('forwardclusters.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defense clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Select the relevant columns for clustering\n",
    "percentile_columns = ['toi_pp_gp_percentile', 'toi_sh_gp_percentile', 'toi_es_gp_percentile', 'toi_ot_per_ot_gp_percentile']\n",
    "data_for_clustering = defense_df[percentile_columns]\n",
    "\n",
    "# Initialize and fit HDBSCAN\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=1)\n",
    "cluster_labels = clusterer.fit_predict(data_for_clustering)\n",
    "\n",
    "# Add the cluster labels to your DataFrame\n",
    "defense_df['cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate plots with ability to isolate by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from umap import UMAP\n",
    "\n",
    "\n",
    "# Reducing to 2D space using UMAP\n",
    "umap_model = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric=\"cosine\")\n",
    "percentile_columns = ['toi_pp_gp_percentile', 'toi_sh_gp_percentile', 'toi_es_gp_percentile', 'toi_ot_per_ot_gp_percentile']\n",
    "reduced_embeddings = umap_model.fit_transform(defense_df[percentile_columns])\n",
    "\n",
    "# Add the reduced 2D embeddings to the DataFrame\n",
    "defense_df['x'] = reduced_embeddings[:, 0]\n",
    "defense_df['y'] = reduced_embeddings[:, 1]\n",
    "\n",
    "# Create the scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "    x=defense_df['x'],\n",
    "    y=defense_df['y'],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, opacity=0.7),\n",
    "    text=defense_df.apply(lambda row: f\"Player: {row['player']}<br>PP Percentile: {row['toi_pp_gp_percentile']}<br>SH Percentile: {row['toi_sh_gp_percentile']}<br>ES Percentile: {row['toi_es_gp_percentile']}<br>OT Percentile: {row['toi_ot_per_ot_gp_percentile']}\", axis=1),\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Stylize layout\n",
    "fig.update_layout(\n",
    "    template=\"simple_white\",\n",
    "    title={\n",
    "        \"text\": \"<b>Defence Percentiles Mapped to 2D Space</b>\",\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"yanchor\": \"top\",\n",
    "        \"font\": dict(size=22, color=\"Black\"),\n",
    "    },\n",
    "    width=1200,\n",
    "    height=750,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(visible=False)\n",
    "fig.update_yaxes(visible=False)\n",
    "\n",
    "# Show the plot\n",
    "fig.write_html('defence_clusters.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from umap import UMAP\n",
    "\n",
    "def plot_hdbscan_clusters(df, cluster_labels):\n",
    "    # Reduce dimensionality with UMAP\n",
    "    umap = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine')\n",
    "    reduced_embeddings = umap.fit_transform(df[['toi_pp_gp_percentile', 'toi_sh_gp_percentile', \n",
    "                                                'toi_es_gp_percentile', 'toi_ot_per_ot_gp_percentile']])\n",
    "    \n",
    "    df['x'] = reduced_embeddings[:, 0]\n",
    "    df['y'] = reduced_embeddings[:, 1]\n",
    "    df['cluster'] = cluster_labels\n",
    "    \n",
    "    \n",
    "    # Initialize the Plotly figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add traces for each cluster\n",
    "    for cluster in df['cluster'].unique():\n",
    "        cluster_data = df[df['cluster'] == cluster]\n",
    "        fig.add_trace(go.Scattergl(\n",
    "            x=cluster_data['x'],\n",
    "            y=cluster_data['y'],\n",
    "            mode='markers',\n",
    "            marker=dict(size=8, opacity=0.7),\n",
    "            name=f'Cluster {cluster}',\n",
    "            text=[f\"{player}<br>PP: {pp:.2f}<br>SH: {sh:.2f}<br>ES: {es:.2f}<br>OT: {ot:.2f}\" \n",
    "                  for player, pp, sh, es, ot in zip(cluster_data['player'], cluster_data['toi_pp_gp_percentile'], \n",
    "                                                     cluster_data['toi_sh_gp_percentile'], \n",
    "                                                     cluster_data['toi_es_gp_percentile'], \n",
    "                                                     cluster_data['toi_ot_per_ot_gp_percentile'])]\n",
    "        ))\n",
    "\n",
    "    # Update layout to allow isolating clusters via the legend\n",
    "    fig.update_layout(\n",
    "        title='HDBSCAN Clusters of NHL Players',\n",
    "        xaxis_title='UMAP Dimension 1',\n",
    "        yaxis_title='UMAP Dimension 2',\n",
    "        legend_title='Cluster',\n",
    "        hovermode='closest',\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "fwd_iso_fig = plot_hdbscan_clusters(forwards_df, forwards_df['cluster'])\n",
    "fwd_iso_fig.write_html('fwd_clusters_iso.html')\n",
    "\n",
    "def_iso_fig = plot_hdbscan_clusters(forwards_df, forwards_df['cluster'])\n",
    "def_iso_fig.write_html('def_clusters_iso.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
